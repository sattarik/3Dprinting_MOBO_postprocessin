{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "broke-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import io\n",
    "\n",
    "from random import seed\n",
    "from random import randint\n",
    "\n",
    "from argparse import ArgumentParser, Namespace\n",
    "import yaml\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# default is to maximize the objectives\n",
    "import time as time\n",
    "import copy\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "# example of a gaussian process surrogate function\n",
    "from math import sin\n",
    "from math import pi\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "from numpy import asarray\n",
    "from numpy.random import normal\n",
    "from numpy.random import uniform\n",
    "from numpy.random import random\n",
    "from numpy import cov\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "\n",
    "\n",
    "from autooed.utils.sampling import lhs\n",
    "import random\n",
    "#import xgboost as xgb\n",
    "#from xgboost import XGBRegressor\n",
    "#from xgboost import plot_tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from sklearn.inspection import partial_dependence, plot_partial_dependence\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "# loocv to manually evaluate the performance of a random forest classifier\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "\n",
    "from scipy.stats import pearsonr as pearsonr\n",
    "from scipy import ndimage, misc\n",
    "import pickle\n",
    "import re\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "from chainer_chemistry.datasets.molnet import get_molnet_dataset\n",
    "# the package is in the same directory\n",
    "# get Today's date from python!\n",
    "from datetime import datetime\n",
    "from autooed.utils.sampling import lhs\n",
    "from autooed.problem import build_problem\n",
    "from autooed.mobo import build_algorithm\n",
    "from autooed.utils.seed import set_seed\n",
    "from autooed.utils.initialization import generate_random_initial_samples, load_provided_initial_samples\n",
    "from autooed.utils.plot import plot_performance_space, plot_performance_metric\n",
    "from autooed.utils.plot import plot_performance_space_diffcolor\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from arguments import get_args\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aerial-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### preprocessing \n",
    "# printability as Y\n",
    "df = pd.read_csv('Yuchao_20220726.csv')\n",
    "\n",
    "Printability = np.asarray (df['Printability']).reshape(1,-1).T\n",
    "Tg = np.asarray (df['Tg']).reshape(1,-1).T\n",
    "Tg[np.isnan(Tg)] = 200\n",
    "Tg_group = [1 if 10<i<60 else 0 for i in Tg]\n",
    "Tg_group = np.array(Tg_group)\n",
    "\n",
    "toughness = np.asarray (df['Toughness(MJ/m3)']).reshape(1,-1).T\n",
    "toughness[np.isnan(toughness)] = 0\n",
    "strength = np.asarray (df['Tensile_Strength(MPa)']).reshape(1,-1).T\n",
    "strength[np.isnan(strength)] = 0\n",
    "strain = np.asarray (df['Tensile_Strain_percentage']).reshape(1,-1).T\n",
    "strain[np.isnan(strain)] = 0\n",
    "\n",
    "Y0 = Printability\n",
    "Y = np.where(Y0 == 'Y', 1, 0)\n",
    "\n",
    "#X_ = df.to_numpy()\n",
    "A_Ratio = np.asarray (df['R1(HA)']).reshape(1,-1)\n",
    "B_Ratio = np.asarray (df['R2(IA)']).reshape(1,-1)\n",
    "C_Ratio = np.asarray (df['R3(NVP)']).reshape(1,-1)\n",
    "D_Ratio = np.asarray (df['R4(AA)']).reshape(1,-1)\n",
    "E_Ratio = np.asarray (df['R5(HEAA)']).reshape(1,-1)\n",
    "F_Ratio = np.asarray (df['R6(IBOA)']).reshape(1,-1)\n",
    "\n",
    "# did not consider F_Ratio, since we do not have it in optimization\n",
    "X_ = np.concatenate((A_Ratio.T, B_Ratio.T, C_Ratio.T, D_Ratio.T, E_Ratio.T), axis=1)\n",
    "\n",
    "\n",
    "# load monomers descriptors\n",
    "df = pd.read_csv('monomers_info.csv')\n",
    "energy = np.array (-df['dft_sp_E_RB3LYP'])\n",
    "pol_area = np.array (df['polar_surface_area'])\n",
    "complexity = np.array (df['complexity'])\n",
    "HA = np.array (df['HA'])\n",
    "solubility = np.array (df['solubility_sqrt_MJperm3'])\n",
    "solubility_d = np.array (df['solubility_dipole'])\n",
    "solubility_h = np.array (df['solubility_h'])\n",
    "solubility_p = np.array (df['solubility_p'])\n",
    "\n",
    "X0 = np.concatenate((A_Ratio.T, B_Ratio.T, C_Ratio.T, D_Ratio.T, E_Ratio.T, F_Ratio.T), axis=1)\n",
    "X_energy = np.multiply (X0, energy)\n",
    "#X_pol_area = np.multiply (X0, pol_area)\n",
    "X_complexity = np.multiply (X0, complexity)\n",
    "X_HA = np.multiply (X0, HA)\n",
    "X_solubility_d = np.multiply (X0, solubility_d)\n",
    "X_solubility_h = np.multiply (X0, solubility_h)\n",
    "X_solubility_p = np.multiply (X0, solubility_p)\n",
    "\n",
    "X = np.concatenate ((X_energy, X_complexity, X_HA, \n",
    "                    X_solubility_d, X_solubility_h, X_solubility_p), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unnecessary-begin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 50\n",
      "better accuracy found for: 4 50\n",
      "4 100\n",
      "5 50\n",
      "better accuracy found for: 5 50\n",
      "5 100\n",
      "6 50\n",
      "6 100\n",
      "8 50\n",
      "8 100\n",
      "10 50\n",
      "10 100\n"
     ]
    }
   ],
   "source": [
    "# find the best hyperparameters for RF printability\n",
    "# best: max_depth = 5, n_estimators = 50\n",
    "max_accuracy = 0\n",
    "min_std = 1\n",
    "parameter_pool = pd.DataFrame()\n",
    "max_depths = [4, 5, 6, 8, 10]\n",
    "#min_samples_splits = [2, 3]\n",
    "n_estimatorsS = [50, 100]\n",
    "\n",
    "best_parameters = pd.DataFrame()\n",
    "best_parameters['max_depth'] = []\n",
    "best_parameters['n_estimators'] = []\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "for parameters in itertools.product(max_depths, n_estimatorsS):\n",
    "    accuracy = list()\n",
    "    accuracy_std = list()\n",
    "    max_depth, n_estimators = parameters[0], parameters[1]\n",
    "    print (max_depth, n_estimators)\n",
    "    for i in range (10):\n",
    "        RF_print = RandomForestClassifier(random_state=10*i, \n",
    "                                          max_depth = max_depth, \n",
    "                                          n_estimators = n_estimators)\n",
    "                                          #min_samples_split=min_samples_split)\n",
    "        scores = cross_val_score(RF_print, X, Tg_group, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "        #print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "        accuracy.append(mean(scores))\n",
    "        accuracy_std.append(std(scores))\n",
    "    if mean(accuracy)>max_accuracy:\n",
    "        print ('better accuracy found for:', max_depth, n_estimators)\n",
    "        max_accuracy = mean(accuracy)\n",
    "        min_std = mean(accuracy_std)\n",
    "        best_parameters['max_depth'] = [max_depth] \n",
    "        best_parameters['n_estimators'] = [n_estimators]\n",
    "    elif mean(accuracy) == max_accuracy:\n",
    "        if mean(accuracy_std) < min_std:\n",
    "            print ('better accuracy found for:', max_depth, n_estimators)\n",
    "            max_accuracy = mean(accuracy)\n",
    "            min_std = mean(accuracy_std)\n",
    "            best_parameters['max_depth'] = [max_depth] \n",
    "            best_parameters['n_estimators'] = [n_estimators]\n",
    "            print('Accuracy: %.3f (%.3f)' % (mean(accuracy), std(accuracy_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "institutional-wilderness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 90, 'verbose': 0, 'warm_start': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-898841b278d9>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  RF_print.fit(X, Y)\n"
     ]
    }
   ],
   "source": [
    "RF_print = RandomForestClassifier(random_state=10*i, \n",
    "                                  max_depth = best_parameters['max_depth'][0], \n",
    "                                  n_estimators = best_parameters['n_estimators'][0])\n",
    "RF_print.fit(X, Y)\n",
    "Yhat = RF_print.predict(X)\n",
    "acc = accuracy_score(Y, Yhat)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print (RF_print.get_params(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hollywood-target",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 50\n",
      "better accuracy found for: 4 50\n",
      "4 100\n",
      "better accuracy found for: 4 100\n",
      "5 50\n",
      "better accuracy found for: 5 50\n",
      "5 100\n",
      "6 50\n",
      "6 100\n",
      "8 50\n",
      "8 100\n",
      "10 50\n",
      "10 100\n",
      "0.9170731707317075 0.27348813456895726\n"
     ]
    }
   ],
   "source": [
    "# find the best hyperparameters for RF Tg\n",
    "# best: max_depth = 5, n_estimators = 50\n",
    "max_accuracy = 0\n",
    "min_std = 1\n",
    "parameter_pool = pd.DataFrame()\n",
    "max_depths = [4, 5, 6, 8, 10]\n",
    "#min_samples_splits = [2, 3]\n",
    "n_estimatorsS = [50, 100]\n",
    "\n",
    "best_parameters = pd.DataFrame()\n",
    "best_parameters['max_depth'] = []\n",
    "best_parameters['n_estimators'] = []\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "for parameters in itertools.product(max_depths, n_estimatorsS):\n",
    "    accuracy = list()\n",
    "    accuracy_std = list()\n",
    "    max_depth, n_estimators = parameters[0], parameters[1]\n",
    "    print (max_depth, n_estimators)\n",
    "    for i in range (10):\n",
    "        RF_print = RandomForestClassifier(random_state=10*i, \n",
    "                                          max_depth = max_depth, \n",
    "                                          n_estimators = n_estimators)\n",
    "                                          #min_samples_split=min_samples_split)\n",
    "        scores = cross_val_score(RF_print, X, Y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "        #print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "        accuracy.append(mean(scores))\n",
    "        accuracy_std.append(std(scores))\n",
    "    if mean(accuracy)>max_accuracy:\n",
    "        print ('better accuracy found for:', max_depth, n_estimators)\n",
    "        max_accuracy = mean(accuracy)\n",
    "        min_std = mean(accuracy_std)\n",
    "        best_parameters['max_depth'] = [max_depth] \n",
    "        best_parameters['n_estimators'] = [n_estimators]\n",
    "    elif mean(accuracy) == max_accuracy:\n",
    "        if mean(accuracy_std) < min_std:\n",
    "            print ('better accuracy found for:', max_depth, n_estimators)\n",
    "            max_accuracy = mean(accuracy)\n",
    "            min_std = mean(accuracy_std)\n",
    "            best_parameters['max_depth'] = [max_depth] \n",
    "            best_parameters['n_estimators'] = [n_estimators]\n",
    "            print('Accuracy: %.3f (%.3f)' % (mean(accuracy), std(accuracy_std)))\n",
    "print (max_accuracy, min_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "finnish-locator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 90, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "RF_Tg = RandomForestClassifier(random_state=10*i, \n",
    "                                  max_depth = best_parameters['max_depth'][0], \n",
    "                                  n_estimators = best_parameters['n_estimators'][0])\n",
    "RF_Tg.fit(X, Tg_group)\n",
    "Yhat = RF_Tg.predict(X)\n",
    "acc = accuracy_score(Tg_group, Yhat)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print (RF_Tg.get_params(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "entitled-search",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 1.  ],\n",
       "       [0.06, 0.94],\n",
       "       [0.24, 0.76],\n",
       "       [0.26, 0.74],\n",
       "       [0.04, 0.96],\n",
       "       [0.  , 1.  ],\n",
       "       [0.12, 0.88],\n",
       "       [0.  , 1.  ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.64, 0.36],\n",
       "       [0.78, 0.22],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.76, 0.24],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.28, 0.72],\n",
       "       [0.  , 1.  ],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.06, 0.94],\n",
       "       [0.02, 0.98],\n",
       "       [0.04, 0.96],\n",
       "       [0.02, 0.98],\n",
       "       [0.08, 0.92],\n",
       "       [0.02, 0.98],\n",
       "       [0.94, 0.06],\n",
       "       [0.98, 0.02],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.92, 0.08],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.82, 0.18],\n",
       "       [0.08, 0.92],\n",
       "       [0.84, 0.16],\n",
       "       [0.96, 0.04],\n",
       "       [1.  , 0.  ],\n",
       "       [0.18, 0.82],\n",
       "       [0.94, 0.06],\n",
       "       [0.  , 1.  ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Tg.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "agreed-socket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tg_group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
